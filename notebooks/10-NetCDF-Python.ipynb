{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The netCDF file format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [netCDF](https://www.unidata.ucar.edu/software/netcdf/) file format is a popular scientific file format for ocean and atmosphere gridded datasets. It is a collection of formats storing arrays:\n",
    "\n",
    "* netCDF classic\n",
    "    * more widespread\n",
    "    * 2 GB file limit (if you don't use the unlimited dimension)\n",
    "    * often preferred for distributing products\n",
    "\n",
    "* netCDF 64 bit offset\n",
    "    * supports larger files\n",
    "\n",
    "* NetCDF4\n",
    "    * based on [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format)\n",
    "    * allows compression\n",
    "    * multiple unlimited variables\n",
    "\n",
    "netCDF was developed by Unidata-UCAR with the aim of storing climate model data (3D + time). netCDF format allows auxilary information about each variable to be added. It can have a readable text equivalent (e.g. using [ncdump](http://www.bic.mni.mcgill.ca/users/sean/Docs/netcdf/guide.txn_79.html#:~:text=The%20ncdump%20tool%20generates%20an,variable%20data%20in%20the%20file.&text=Thus%20ncdump%20and%20ncgen%20can,between%20binary%20and%20ASCII%20representations.)) and can be used with [Climate and Forecast (CF)](http://cfconventions.org/) data convention.\n",
    "\n",
    "## Data model\n",
    "\n",
    "|                 |                                                              |\n",
    "| --------------- | -------------------------------------------------------------|\n",
    "| **Dimensions**  | describe the axes of the data arrays                         |\n",
    "| **Variables**   | N-dimensional arrays of data                                 |\n",
    "| **Attributes**  | small note/supplementary metadata as annotations to the file |\n",
    "\n",
    "\n",
    "Ocean model dataset example:\n",
    " \n",
    "|   |   |   |   |   |\n",
    "|---|---|---|---|---|\n",
    "| Dimensions | lat | lon | depth | time |\n",
    "| Variable | Temperature | Salinity |  |  |\n",
    "| Global attribute | Geographic grid type | History |  |  |\n",
    "| Variable attributes | Long_name: \"sea water temperature\" | Missing_value: 1.09009E36 | Units: deg. C | range: -2:50 |\n",
    "\n",
    "<br>\n",
    "<img src=\"../figures/dataset-diagram.png\" style=\"width:600px\";/>\n",
    "\n",
    "## Python packages\n",
    "\n",
    "The main Python interface to the netCDF C library is [netCDF4](http://unidata.github.io/netcdf4-python/) package. In this tutorial, however, we will use a more high-level package called [xarray](http://xarray.pydata.org/en/stable/index.html).\n",
    "\n",
    "Note: another good package for netCDF files is [iris](http://scitools.org.uk/iris/) (developed by the UK Met Office).\n",
    "\n",
    "## Working with netCDF files using xarray\n",
    "\n",
    "[xarray](http://xarray.pydata.org/) package brings the power of pandas to environmental sciences by providing N-dimensional variants of the core pandas data structures.\n",
    "\n",
    "| Pandas | xarray  |\n",
    "|---|---|\n",
    "| Series  | DataArray  |\n",
    "| DataFrame  | Dataset  |\n",
    "\n",
    "\n",
    "DataArray uses names of dimensions making it easier to track than by using axis numbers.\n",
    "\n",
    "Compare:\n",
    "```python\n",
    "# xarray style\n",
    ">>> ds.sel(time='2018-01-12').max(dim='ensemble')\n",
    "\n",
    "# numpy style\n",
    ">>> array[[0, 1, 2, 3], :, :].max(axis=2)\n",
    "```\n",
    "\n",
    "(Taken from Stephan Hoyer's [ECMWF talk](https://docs.google.com/presentation/d/16CMY3g_OYr6fQplUZIDqVtG-SKZqsG8Ckwoj2oOqepU/edit#slide=id.g2b68f9254d_1_27))\n",
    "\n",
    "**Main advantages of using xarray versus plain netCDF4:**\n",
    "* intelligent selection along labelled dimensions (and also indexes)\n",
    "* groupby operations\n",
    "* data alignment\n",
    "* IO (netcdf)\n",
    "* conversion from and to pandas `DataFrame` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything that we are going to need\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import a local dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GETM = xr.open_dataset('../data/cefas_GETM_nwes.nc4')\n",
    "GETM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this file holds bathymetry, height and tempearture data for a gridded area of the North West European Shelf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GETM.dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print these dimensions to see the extent of the netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GETM.latc\n",
    "#GETM.lonc\n",
    "#GETM.time\n",
    "#GETM.level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(GETM.coords['latc']))\n",
    "GETM.coords['latc'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List name of dataset attributes\n",
    "GETM.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List variable names\n",
    "GETM.data_vars.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells  us that bathymetry is 2D, varying only with latitude and longitude. Height and temperature are 4D, varying with time and model level as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract variable from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = GETM['temp']\n",
    "print(type( temp ))\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access variable attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print variable attributes\n",
    "\n",
    "for at, val in temp.attrs.items():\n",
    "    print(f'{at:<15}: {val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[0, 0, 90, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.values[0, 0, 90, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and selecting data\n",
    "\n",
    "Xarray indexing overview can be found [here](http://xarray.pydata.org/en/stable/getting-started-guide/quick-overview.html#indexing). The graphics below is a summary what one can do:\n",
    "\n",
    "<br>\n",
    "<img src=\"../figures/xarray_indexing_table.png\" style=\"width:600px\";/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positional by integer\n",
    "print(temp[0, 2, :, :].shape)\n",
    "\n",
    "# positional by label\n",
    "print(temp.loc['1996-02-02T01:00:00', :, :, :].shape)\n",
    "\n",
    "# by name and integer\n",
    "print(temp.isel(level=1, latc=90, lonc=100).shape)\n",
    "\n",
    "# by name and label\n",
    "print(temp.sel(time='1996-02-02T01:00:00').shape)\n",
    "# temp.loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define selection using nearest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GETM.sel(level=1)['temp']\n",
    "GETM['temp'].sel(level=2, lonc=-5.0, latc=50.0, method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tolerance for label selection (lat=-50 should not yield data)\n",
    "tol = 0.5\n",
    "\n",
    "try:\n",
    "    GETM['temp'].sel(level=1, lonc=-5.0, latc=-50.0, method='nearest', tolerance=tol)\n",
    "except KeyError:\n",
    "    print(f'ERROR: outside tolerance of {tol}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a general mapping function using cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_map():\n",
    "    # create figure and axes instances\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection=ccrs.Stereographic(central_latitude=60))\n",
    "    #ax.coastlines(resolution='50m', linewidth=0.5)\n",
    "    ax.set_extent([-10, 15, 49, 60], crs=ccrs.PlateCarree())\n",
    "    \n",
    "    gl = ax.gridlines(draw_labels=False)\n",
    "    \n",
    "    feature = cartopy.feature.NaturalEarthFeature(name='coastline',\n",
    "                                                  category='physical',\n",
    "                                                  scale='50m',\n",
    "                                                  edgecolor='0.5',\n",
    "                                                  facecolor='0.8')\n",
    "    ax.add_feature(feature)\n",
    "    return fig, ax\n",
    "\n",
    "make_map()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latc = GETM.coords['latc']\n",
    "lonc = GETM.coords['lonc']\n",
    "\n",
    "var = GETM.temp.sel(time='1996-02-02T01:00:00', level=21)\n",
    "\n",
    "# create arrays of coordinates for contourf\n",
    "# lon2d, lat2d = np.meshgrid(lonc, latc)\n",
    "\n",
    "fig, ax = make_map()\n",
    "# draw filled contours.\n",
    "h = ax.contourf(lonc, latc, var, 50, cmap=plt.cm.coolwarm, transform=ccrs.PlateCarree())\n",
    "\n",
    "# add colorbar.\n",
    "cbar = fig.colorbar(h)\n",
    "cbar.set_label(var.units)\n",
    "\n",
    "# add title\n",
    "ax.set_title(f'A slice of {var.long_name}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But often, this will do\n",
    "# GETM.temp.isel(time=0, level=0).plot();\n",
    "GETM.temp.sel(time='1996-02-02T01:00:00', level=21).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = GETM['temp'].isel(time=0, level=4)\n",
    "bottom = GETM['temp'].isel(time=0, level=0)\n",
    "\n",
    "diff = top - bottom\n",
    "\n",
    "diff.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate average along a dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over time\n",
    "time_ave = GETM['temp'].mean('time')\n",
    "\n",
    "# average over time and level (vertical)\n",
    "time_and_level_ave = GETM['temp'].mean(['time','level'])\n",
    "\n",
    "time_and_level_ave.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zonal average (vertical)\n",
    "timelon_ave = GETM['temp'].mean(['time','lonc']).isel(level=4)\n",
    "\n",
    "timelon_ave.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **xarray** we have the data access power of **netCDF4** with all the intelligent selection, arithmetic, statistical methods and plotting of **pandas**.\n",
    "\n",
    "## A dataset can easily be saved to a netCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = GETM[['temp']].mean('time','level')\n",
    "ds.to_netcdf('../data/temp_avg_level_time.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "* Extract the bathymetry\n",
    "* Extract the time averaged seabed temperature at level = 0\n",
    "* Produce a scatter plot of depth vs. seabed temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GETM.data_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import remote dataset\n",
    "\n",
    "xarray supports [OpenDAP](https://www.opendap.org/). This means that a dataset can be accessed remotely and subsetted as needed. Only the selected parts are downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_data = xr.open_dataset(\n",
    "      'http://iridl.ldeo.columbia.edu/SOURCES/.OSU/.PRISM/.monthly/dods',\n",
    "      decode_times=False)\n",
    "remote_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 2\n",
    "Import data from a netCDF or csv file and start exploring it. Some ideas:\n",
    "- Use pandas to get quick statistics\n",
    "- Do some data cleaning and calculations with numpy\n",
    "- Plot it up with matplotlib, pandas, seaborn or cartopy as you prefer\n",
    "\n",
    "I encourage you to use your own data if you have some. If not, we have some sample datasets you can explore.\n",
    "\n",
    "### Earthquake data (csv file)\n",
    "US Geological Survey (USGS) provides various [earthquakes data](https://earthquake.usgs.gov/data/data.php#eq) on a global scale. Its Earthquake Catalog contains earthquake source parameters (e.g. hypocenters, magnitudes, phase picks and amplitudes) and other products (e.g. moment tensor solutions, macroseismic information, tectonic summaries, maps) produced by contributing seismic networks.\n",
    "\n",
    "If you follow this [link](http://earthquake.usgs.gov/earthquakes/search/), you can search throught the catalog and filter data by the magnitude, time and geographic region. In the `data/` folder, we provide an [example dataset](../data/earthquakes_2015_2016_gt45.csv) of earthquakes with magnitude >4.5 that occurred around the world over the period of a year.\n",
    "\n",
    "To get you started, the following cell loads the data into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv('../data/earthquakes_2015_2016_gt45.csv', parse_dates = ['time',], index_col='time')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to build your project on these data, some possible ideas are:\n",
    "* `pandas` package will be most useful to read in the data, as well as analyse them\n",
    "* Use `cartopy` to plot the data using longitude and latitude columns\n",
    "* Explore `pandas`' `groupby()` method, which you can use to aggregate data by time or other parameter\n",
    "* Create a histogram of earthquakes magnitude\n",
    "\n",
    "### Arctic Sea Ice (netCDF files)\n",
    "* In this project you are offered to use NOAA/NSIDC Climate Data Record of Passive Microwave Sea Ice Concentration.\n",
    "* In the `../data/` directory, there are 2 netCDF files `seaice_conc_monthly*` that correspond to September 1991  and September 2012 .\n",
    "* If you want to download data for other months, visit the [NSIDC's data portal](https://nsidc.org/data/search/#keywords=sea+ice/sortKeys=score,,desc/facetFilters=%257B%257D/pageNumber=1/itemsPerPage=25).\n",
    "\n",
    "For this project, I recommend that you:\n",
    "* use `xarray` for opening and reading the netCDF files\n",
    "* use `cartopy` for creating a plot with a correct map projection\n",
    "* use appropriate colormaps for the sea ice concentration and difference between the two years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code to get you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cartopy.crs as ccrs\n",
    "# import matplotlib.pyplot as plt\n",
    "# import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds1 = xr.open_dataset('../data/seaice_conc_monthly_nh_f08_199109_v02r00.nc')\n",
    "# ds2 = xr.open_dataset('../data/seaice_conc_monthly_nh_f17_201209_v02r00.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* https://www.unidata.ucar.edu/software/netcdf/docs/netcdf_data_model.html\n",
    "* http://xarray.pydata.org/en/stable/getting-started-guide/quick-overview.html#indexing"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
