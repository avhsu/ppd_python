{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to pandas\n",
    "\n",
    "[pandas](https://pandas.pydata.org/docs/) is a Python package for working with structured datasets, e.g. it is perfectly suited for observational/statistical datasets, having many similarities with Excel spreadsheets.\n",
    "\n",
    "## Key features\n",
    "- easy handling of missing data\n",
    "- columns can be inserted and deleted from loaded data sets (size mutability)\n",
    "- data can be automatically or explicitly aligned to a set of labels (data alignment)\n",
    "- group by functionality to perform split-apply-combine operations on data sets\n",
    "- easy to convert ragged, differently-indexed data in other Python and NumPy data structures into pandas objects\n",
    "- intelligent label-based slicing, fancy indexing, and subsetting of large data sets\n",
    "- intuitive merging and joining data sets\n",
    "- flexible reshaping and pivoting of data sets\n",
    "- hierarchical labeling of axes (possible to have multiple labels per tick)\n",
    "- robust I/O (Input/Output) tools for loading data from flat files (CSV and delimited), Excel files, databases, and saving/loading data from the ultrafast HDF5 format\n",
    "- time series - specific functionalities\n",
    "\n",
    "pandas is built on top of [`numpy`](https://numpy.org/doc/stable/index.html) and is intended to integrate well within a scientific computing environment with many other 3rd party libraries.\n",
    "\n",
    "The community standard to import pandas is to use `pd` alias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import other useful modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary data structures of pandas\n",
    "\n",
    "### Series\n",
    "\n",
    "Series is a 1-dimensional numpy array with axis labels. Can be created with a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'a': 1, 'b': 2, 'c': 3}\n",
    "ser = pd.Series(data=d, index=['a', 'b', 'c'])\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame \n",
    "\n",
    "DataFrame is a 2-dimensional tabular data. Similarly, can be created with a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'temperature': [31.5, 32.5], 'pressure': [100.0, 200.0]}\n",
    "df = pd.DataFrame(data=d)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The following cell finds the path to the data on your system so we can read it in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path # A module for dealing with paths that is operating system agnostic\n",
    "notebook_dir = Path.cwd() # Get the current working directory\n",
    "base_dir = notebook_dir.parent.absolute() # Get the parent directory (folder that contains our working directory)\n",
    "data_dir = base_dir / 'data'# Get diretory where the data is stored\n",
    "fname = data_dir / 'ship_ctd_short.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from a `.csv` file can be loaded using [`pandas.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function. For other data formats, check how to load them [here](https://pandas.pydata.org/pandas-docs/stable/reference/io.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_data = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interrogate `ctd_data` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ctd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View just the top of data\n",
    "ctd_data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find shape of the data\n",
    "print(ctd_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find data type in each column\n",
    "print(ctd_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the last rows of data\n",
    "# Note the optional argument for number of rows (available for head() too)\n",
    "ctd_data.tail(n=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get descriptors for the **vertical** axis (rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ctd_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get descriptors for the **horizontal** axis (columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ctd_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get general information at once including memory usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting a column\n",
    "\n",
    "A pandas `Series` can be extracted from a `DataFrame` using one of its columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = ctd_data['Temperature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of its attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(temp))\n",
    "print(temp.dtype)\n",
    "print(temp.shape)\n",
    "print(temp.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note it has both the index and data coloumn, but the shape is still only 1D. The index is more like a coordinate rather than data in itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy as pandas' backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always possible to fall back to a `numpy` array to pass on to scientific libraries that need them: SciPy, scikit-learn, etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ctd_data['Temperature'].values)\n",
    "print(\"ctd_data is a\", type(ctd_data['Temperature'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">The truth about data science: cleaning your data is 90% of the work. Fitting the model is easy. Interpreting the results is the other 90%.</p>&mdash; Jake VanderPlas (@jakevdp) <a href=\"https://twitter.com/jakevdp/status/742406386525446144\">June 13, 2016</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "### Renaming columns\n",
    "\n",
    "Column names in our data don't have any units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ctd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know the units of the variables, we can rename the columns to include these units. This is especailly useful if you plan to carry out unit conversions later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_data.columns = ['Depth_m', 'Temperature_C', 'Oxygen_ml/l', 'Irradiance', 'Salinity_psu']\n",
    "ctd_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the use of underscores `_` in the renaming. It may not be pretty, but putting spaces in variable names will cause problems later on in your processing.\n",
    "\n",
    "### Deleting columns\n",
    "\n",
    "Let's drop Irradiance collumn from the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_data = ctd_data.drop('Irradiance', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing index\n",
    "It would make more sense to have Depth column as the index, as the other variables are expected to vary with depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_data.set_index('Depth_m', inplace=True)\n",
    "ctd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try calling `plot()` method of the `ctd_data` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_data.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explicitly pass nicer labels to legend if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A':26, 'B':20}, index=['N'])\n",
    "ax = ctd_data.plot()\n",
    "ax.legend([\"Temperature $\\mathrm{(^{\\circ}C}$)\", \"Oxygen (ml/l)\", \"Salinity (psu)\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we pass `subplots=True` as an argument of the `plot()` method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# axes = ctd_data.plot( ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to create other useful plots using `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use matplotlib to initialise your figure with 2 subplots\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(8,4))\n",
    "\n",
    "# Make boxplots with specific columns in each subplot\n",
    "ctd_data.boxplot(ax=ax0, column=['Salinity_psu'])\n",
    "ctd_data.boxplot(ax=ax1, column=['Oxygen_ml/l'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More options for visualisation can be looked at [the pandas website](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html).\n",
    "\n",
    "## Exporting data\n",
    "\n",
    "One of pandas best features is how it simplifies writing text to a `.csv` (comma seperated value) text file that can be read easily by programs like Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_data.to_csv(data_dir/'ship_ctd_short_clean.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "You can print a summary of main statistics for the whole DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ctd_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can still call individual ones like in numpy, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ctd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing correlations\n",
    "\n",
    "Both `Series` and `DataFrames` have a `corr()` method to compute the correlation coefficient.\n",
    "\n",
    "If series are already grouped into a `DataFrame`, computing all correlation coefficients is trivial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to visualise this correlation matrix, uncomment the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# p = ax.imshow(ctd_data.corr(), interpolation=\"nearest\", cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "# ax.set_xticks(np.arange(len(ctd_data.corr().columns)))\n",
    "# ax.set_yticks(np.arange(len(ctd_data.corr().index)))\n",
    "# ax.set_xticklabels(ctd_data.corr().columns)\n",
    "# ax.set_yticklabels(ctd_data.corr().index)\n",
    "# fig.colorbar(p)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling operations\n",
    "\n",
    "Pandas includes functionality to do [rolling means](https://en.wikipedia.org/wiki/Moving_average), sums, and more, given a specified window size. This is very useful for smoothing noisy data.\n",
    "\n",
    "First we will create some noisy data from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_data = ctd_data['Temperature_C']\n",
    "\n",
    "# Randomise data to make it super noisy\n",
    "noisy_data = noisy_data * 2*random.rand(len(noisy_data)) + noisy_data**2\n",
    "print(noisy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(7,3))\n",
    "ctd_data['Temperature_C'].plot(ax=ax[0])\n",
    "noisy_data.plot(ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_roll = noisy_data.rolling(window=50)\n",
    "noisy_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_roll.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_data.plot(label=\"Noisy data\")\n",
    "noisy_roll.mean().plot(label=\"Rolling mean (window = 50)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other rolling functions, such as [`sum()`](https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.sum.html), and you can even use the [`win_type`](https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows) argument to use change the window type.\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "Create a new rolling object from the noisy data and apply the `win_type` argument, and explore the result. \n",
    "\n",
    "Two common types are `'triang'` and `'gaussian'`.\n",
    "\n",
    "Note: for gaussian you'll have to specify a standard deviation argument (written as `std`) \n",
    "when you apply the `sum()` or `mean()` function afterwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames\n",
    "\n",
    "`DataFrame` can be created manually, by grouping several `Series` together.\n",
    "\n",
    "We will load two `Series` objects from two `.csv` files and combine them into a `DataFrame`.\n",
    "\n",
    "Data are monthly values of:\n",
    "* Southern Oscillation Index (SOI) - \"a standardized index based on the observed sea level pressure differences between Tahiti and Darwin, Australia\"\n",
    "* Outgoing Longwave Radiation (OLR) - \"a proxy for convective precipitation in the western equatorial Pacific\"\n",
    "\n",
    "Data were downloaded from [NOAA's website](https://www.ncdc.noaa.gov/teleconnections/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soi_df = pd.read_csv('../data/soi.csv', skiprows=1, parse_dates=[0], index_col=0, na_values=-999.9,\n",
    "                     date_parser=lambda x: pd.datetime.strptime(x, '%Y%m'))\n",
    "\n",
    "olr_df = pd.read_csv('../data/olr.csv', skiprows=1, parse_dates=[0], index_col=0, na_values=-999.9,\n",
    "                     date_parser=lambda x: pd.datetime.strptime(x, '%Y%m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'OLR': olr_df.Value,\n",
    "                   'SOI': soi_df.Value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, although the data series do not overlap completely, we can combine them seamlesssly into a dataframe because `pandas` understands datetime objects as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby operations\n",
    "\n",
    "Often, we want to calculate aggregated values across the values of a certain index or column. For example, we can quickly compute monthly averages across all the years in our dataframe as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_means = df.groupby(df.index.month).mean()\n",
    "\n",
    "# Show the result on a plot\n",
    "df_monthly_means.plot()\n",
    "plt.xlabel('Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Least Square (OLS) regressions\n",
    "\n",
    "### Numpy polynomial fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.polynomial import polynomial as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['OLR'].values\n",
    "y = df['SOI'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.isfinite(x) & np.isfinite(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs, stats = P.polyfit(x[idx], y[idx], 1, full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = P.polyval(x, coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, linestyle='', marker='o')\n",
    "plt.plot(x, y2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "x = df['OLR'].values.reshape(-1, 1)\n",
    "y = df['SOI'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(x, y)\n",
    "y_pred = model.predict(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_pred, color=\"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More examples: https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html\n",
    "\n",
    "## Extra tutorials\n",
    "\n",
    "Online tutorials with more in-depth operations used in pandas:\n",
    "\n",
    "* [Kaggle tutorial](https://www.kaggle.com/learn/pandas)\n",
    "* [Pandas official website Getting Started](https://pandas.pydata.org/docs/getting_started/index.html#getting-started)\n",
    "\n",
    "## References\n",
    "* https://github.com/jonathanrocher/pandas_tutorial\n",
    "* https://github.com/koldunovn/python_for_geosciences\n",
    "* http://pandas.pydata.org/pandas-docs/stable/index.html#module-pandas\n",
    "* http://pandas.pydata.org/pandas-docs/stable/10min.html\n",
    "* https://towardsdatascience.com/linear-regression-in-6-lines-of-python-5e1d0cd05b8d"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
